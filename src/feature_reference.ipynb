{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project SHIELD - Feature Extraction Reference\n",
    "\n",
    "This notebook demonstrates the physics-informed feature pipeline for autonomous sensor modality recognition. We extract time-domain, frequency-domain, and stability features from raw sensor signals to classify sensor types based on their characteristic noise profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom SensorDataLoader import SensorDataLoader\nfrom feature_extractor import FeatureExtractor\nfrom freq_domain_analyses import get_psd_welch, get_spectral_slope\nfrom time_domain_analyses import get_statistical_moments\nfrom allan_dev import get_allan_deviation\n\nos.makedirs('figures', exist_ok=True)\nos.makedirs('models', exist_ok=True)\n\nFS = 100.0\nloader = SensorDataLoader(seed=42)\nextractor = FeatureExtractor(fs=FS)\n\nprint(f\"Sampling frequency: {FS} Hz\")\nprint(\"Output directories: figures/, models/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Noise Types\n",
    "\n",
    "Different sensor modalities exhibit different noise colors:\n",
    "- **White noise** (flat PSD): Accelerometers\n",
    "- **Pink noise** (1/f PSD): Gyroscopes, magnetometers\n",
    "- **Brown noise** (1/f^2 PSD): Pressure, temperature sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000\n",
    "\n",
    "white_signal = loader.generate_synthetic_data(N_SAMPLES, noise_type='white').flatten()\n",
    "pink_signal = loader.generate_synthetic_data(N_SAMPLES, noise_type='pink').flatten()\n",
    "brown_signal = loader.generate_synthetic_data(N_SAMPLES, noise_type='brown').flatten()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 3))\n",
    "for ax, sig, name in zip(axes, [white_signal, pink_signal, brown_signal], ['White', 'Pink', 'Brown']):\n",
    "    ax.plot(sig[:500], linewidth=0.5)\n",
    "    ax.set_title(f'{name} Noise')\n",
    "    ax.set_xlabel('Sample')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PAMAP2 Real Sensor Data\n",
    "\n",
    "The PAMAP2 dataset contains IMU data (accelerometer, gyroscope, magnetometer) and temperature from wearable sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pamap_files = glob.glob('../PAMAP2_Dataset/Protocol/*.dat')\n",
    "print(f\"Found {len(pamap_files)} PAMAP2 subject files\")\n",
    "\n",
    "sensors = loader.load_pamap2(pamap_files[0])\n",
    "sensors = loader.get_stationary_segments(sensors, activities=[2, 3])\n",
    "\n",
    "print(f\"\\nAvailable sensors: {[k for k in sensors.keys() if 'hand' in k]}\")\n",
    "print(f\"Samples after filtering: {len(sensors['timestamp'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time-Domain Feature Extraction\n",
    "\n",
    "Statistical moments characterize the signal amplitude distribution:\n",
    "- **Mean, variance, RMS**: Central tendency and spread\n",
    "- **Skewness, kurtosis**: Distribution shape\n",
    "- **ZCR (zero-crossing rate)**: Signal oscillation frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_white = get_statistical_moments(white_signal)\n",
    "time_features_pink = get_statistical_moments(pink_signal)\n",
    "time_features_brown = get_statistical_moments(brown_signal)\n",
    "\n",
    "time_df = pd.DataFrame({\n",
    "    'White': time_features_white,\n",
    "    'Pink': time_features_pink,\n",
    "    'Brown': time_features_brown\n",
    "}).T\n",
    "\n",
    "print(\"Time-Domain Features by Noise Type:\")\n",
    "time_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "for ax, sig, name in zip(axes, [white_signal, pink_signal, brown_signal], ['White', 'Pink', 'Brown']):\n",
    "    ax.hist(sig, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{name} - Distribution')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frequency-Domain Feature Extraction\n",
    "\n",
    "Power Spectral Density (PSD) reveals the noise color:\n",
    "- **PSD slope**: The log-log slope discriminates noise types\n",
    "  - White: slope ~ 0\n",
    "  - Pink: slope ~ -1\n",
    "  - Brown: slope ~ -2\n",
    "- **Spectral flatness**: Higher for white noise (uniform energy)\n",
    "- **Spectral entropy**: Complexity measure of the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 5))\n\nfor sig, name, color in [(white_signal, 'White', 'blue'), \n                          (pink_signal, 'Pink', 'orange'),\n                          (brown_signal, 'Brown', 'green')]:\n    freqs, power = get_psd_welch(sig, fs=FS)\n    slope = get_spectral_slope(freqs, power)\n    mask = freqs > 0\n    ax.loglog(freqs[mask], power[mask], label=f'{name} (slope={slope:.2f})', \n              color=color, alpha=0.8, linewidth=2)\n\nax.set_xlabel('Frequency (Hz)')\nax.set_ylabel('Power Spectral Density')\nax.set_title('PSD Comparison - Noise Color Identification')\nax.legend()\nax.grid(True, which='both', alpha=0.3)\nplt.tight_layout()\nplt.savefig('figures/psd_noise_colors.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/psd_noise_colors.png\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freq_domain_analyses import extract_freq_features\n",
    "\n",
    "freq_df = pd.DataFrame({\n",
    "    'White': extract_freq_features(white_signal, FS),\n",
    "    'Pink': extract_freq_features(pink_signal, FS),\n",
    "    'Brown': extract_freq_features(brown_signal, FS)\n",
    "}).T\n",
    "\n",
    "print(\"Frequency-Domain Features by Noise Type:\")\n",
    "freq_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stability Features (Allan Deviation)\n",
    "\n",
    "Allan Deviation (ADEV) characterizes sensor stability over different integration times (tau):\n",
    "- **ADEV slope ~ -0.5**: White noise (Angle Random Walk)\n",
    "- **ADEV slope ~ 0**: Flicker noise (Bias Instability)\n",
    "- **ADEV slope ~ +0.5**: Random walk (Rate Random Walk)\n",
    "\n",
    "This is the standard metric for inertial sensor characterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import allantools\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\nfor sig, name, color in [(white_signal, 'White', 'blue'),\n                          (pink_signal, 'Pink', 'orange'),\n                          (brown_signal, 'Brown', 'green')]:\n    max_tau = len(sig) / FS / 2.0\n    taus = np.logspace(np.log10(1.0/FS), np.log10(max_tau), num=20)\n    taus_out, ad, ade, ns = allantools.oadev(sig, rate=FS, data_type='freq', taus=taus)\n    \n    log_t = np.log10(taus_out)\n    log_ad = np.log10(ad)\n    slope, _ = np.polyfit(log_t, log_ad, 1)\n    \n    ax.loglog(taus_out, ad, 'o-', label=f'{name} (slope={slope:.2f})', color=color, alpha=0.8)\n\nax.set_xlabel('Integration Time (tau) [s]')\nax.set_ylabel('Allan Deviation')\nax.set_title('Allan Deviation - Stability Regime Identification')\nax.legend()\nax.grid(True, which='both', alpha=0.3)\nplt.tight_layout()\nplt.savefig('figures/allan_deviation.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/allan_deviation.png\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adev_df = pd.DataFrame({\n",
    "    'White': get_allan_deviation(white_signal, FS),\n",
    "    'Pink': get_allan_deviation(pink_signal, FS),\n",
    "    'Brown': get_allan_deviation(brown_signal, FS)\n",
    "}).T\n",
    "\n",
    "print(\"Allan Deviation Features by Noise Type:\")\n",
    "adev_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Full Feature Dataset from PAMAP2\n",
    "\n",
    "Extract features from all sensor modalities in the PAMAP2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modality_dataset(data_dir, max_files=None):\n",
    "    files = glob.glob(f\"{data_dir}/*.dat\")\n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    \n",
    "    modality_map = {\n",
    "        'accel_16g': 'accelerometer',\n",
    "        'accel_6g': 'accelerometer', \n",
    "        'gyro': 'gyroscope',\n",
    "        'mag': 'magnetometer',\n",
    "        'temp': 'temperature'\n",
    "    }\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    for filepath in files:\n",
    "        print(f\"Processing {filepath.split('/')[-1]}...\")\n",
    "        sensors = loader.load_pamap2(filepath)\n",
    "        sensors = loader.get_stationary_segments(sensors, activities=[2, 3])\n",
    "        \n",
    "        for location in ['hand', 'chest', 'ankle']:\n",
    "            for sensor_type, modality in modality_map.items():\n",
    "                key = f'{location}_{sensor_type}'\n",
    "                data = sensors[key]\n",
    "                \n",
    "                if data.ndim == 1:\n",
    "                    data = data[~np.isnan(data)]\n",
    "                    if len(data) < 1000:\n",
    "                        continue\n",
    "                    df = extractor.process_signal(data, 2.0, 1.0)\n",
    "                    df['modality'] = modality\n",
    "                    all_features.append(df)\n",
    "                else:\n",
    "                    for axis in range(data.shape[1]):\n",
    "                        sig = data[:, axis]\n",
    "                        sig = sig[~np.isnan(sig)]\n",
    "                        if len(sig) < 1000:\n",
    "                            continue\n",
    "                        df = extractor.process_signal(sig, 2.0, 1.0)\n",
    "                        df['modality'] = modality\n",
    "                        all_features.append(df)\n",
    "    \n",
    "    return pd.concat(all_features, ignore_index=True)\n",
    "\n",
    "feature_df = build_modality_dataset('../PAMAP2_Dataset/Protocol', max_files=3)\n",
    "print(f\"\\nDataset shape: {feature_df.shape}\")\n",
    "print(f\"Modalities: {feature_df['modality'].unique()}\")\n",
    "print(f\"\\nSamples per modality:\")\n",
    "print(feature_df['modality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Separability Plots\n",
    "\n",
    "Visualize how well features separate different sensor modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Pairwise Scatter Plots\n",
    "\n",
    "Show relationships between the most discriminative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "top_features = ['psd_slope', 'spectral_flatness', 'zcr', 'rms']\nexisting_features = [f for f in top_features if f in feature_df.columns]\n\nplot_df = feature_df[existing_features + ['modality']].dropna()\nplot_df_sampled = plot_df.groupby('modality').apply(lambda x: x.sample(min(500, len(x)), random_state=42)).reset_index(drop=True)\n\ng = sns.pairplot(plot_df_sampled, vars=existing_features, hue='modality', \n                 palette='tab10', plot_kws={'alpha': 0.5, 's': 20})\ng.fig.suptitle('Pairwise Feature Scatter Plots', y=1.02)\nplt.savefig('figures/pairwise_scatter.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/pairwise_scatter.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 PCA Visualization\n",
    "\n",
    "Project high-dimensional feature space to 2D using Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nmeta_cols = ['window_start_sample', 'window_start_sec', 'modality']\nfeature_cols = [c for c in feature_df.columns if c not in meta_cols]\n\nX = feature_df[feature_cols].fillna(0).values\ny = feature_df['modality'].values\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\nfig, ax = plt.subplots(figsize=(10, 7))\nfor modality in np.unique(y):\n    mask = y == modality\n    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], label=modality, alpha=0.5, s=20)\n\nax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\nax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\nax.set_title('PCA - Modality Clusters')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('figures/pca_clusters.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"Total variance explained by 2 components: {sum(pca.explained_variance_ratio_):.1%}\")\nprint(\"Saved: figures/pca_clusters.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 UMAP Visualization\n",
    "\n",
    "Non-linear dimensionality reduction that preserves local structure better than PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import umap\n\nreducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, n_jobs=1)\nX_umap = reducer.fit_transform(X_scaled)\n\nfig, ax = plt.subplots(figsize=(10, 7))\nfor modality in np.unique(y):\n    mask = y == modality\n    ax.scatter(X_umap[mask, 0], X_umap[mask, 1], label=modality, alpha=0.5, s=20)\n\nax.set_xlabel('UMAP 1')\nax.set_ylabel('UMAP 2')\nax.set_title('UMAP - Modality Clusters')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('figures/umap_clusters.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/umap_clusters.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classification Demo\n",
    "\n",
    "Train a Random Forest classifier to predict sensor modality from extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"\\nTest accuracy: {(y_pred == y_test).mean():.3f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cm = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=le.classes_, yticklabels=le.classes_, ax=ax)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nax.set_title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/confusion_matrix.png\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "importances = pd.DataFrame({\n    'feature': feature_cols,\n    'importance': clf.feature_importances_\n}).sort_values('importance', ascending=True).tail(15)\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.barh(importances['feature'], importances['importance'])\nax.set_xlabel('Importance')\nax.set_title('Top 15 Feature Importances')\nplt.tight_layout()\nplt.savefig('figures/feature_importance.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Saved: figures/feature_importance.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model Artifacts\n",
    "\n",
    "Save trained model, scaler, and label encoder for the prediction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, 'models/rf_classifier.joblib')\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "joblib.dump(le, 'models/label_encoder.joblib')\n",
    "joblib.dump(feature_cols, 'models/feature_columns.joblib')\n",
    "\n",
    "print(\"Saved model artifacts:\")\n",
    "print(\"  - models/rf_classifier.joblib\")\n",
    "print(\"  - models/scaler.joblib\") \n",
    "print(\"  - models/label_encoder.joblib\")\n",
    "print(\"  - models/feature_columns.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction Demo\n",
    "\n",
    "Demonstrate the prediction workflow: raw signal -> features -> modality prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signals = {\n",
    "    'white_noise': loader.generate_synthetic_data(5000, noise_type='white').flatten(),\n",
    "    'pink_noise': loader.generate_synthetic_data(5000, noise_type='pink').flatten(),\n",
    "    'brown_noise': loader.generate_synthetic_data(5000, noise_type='brown').flatten()\n",
    "}\n",
    "\n",
    "for name, signal in test_signals.items():\n",
    "    df = extractor.process_signal(signal, 2.0, 1.0)\n",
    "    X_new = df[feature_cols].fillna(0).values\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    preds = clf.predict(X_new_scaled)\n",
    "    probs = clf.predict_proba(X_new_scaled)\n",
    "    \n",
    "    pred_labels = le.inverse_transform(preds)\n",
    "    most_common = pd.Series(pred_labels).mode()[0]\n",
    "    confidence = (pred_labels == most_common).mean()\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Predicted modality: {most_common}\")\n",
    "    print(f\"  Confidence: {confidence:.1%}\")\n",
    "    print(f\"  Distribution: {pd.Series(pred_labels).value_counts().to_dict()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import SensorPredictor\n",
    "\n",
    "predictor = SensorPredictor(model_path='models/')\n",
    "\n",
    "test_signal = loader.generate_synthetic_data(5000, noise_type='white').flatten()\n",
    "result = predictor.predict(test_signal, fs=100.0)\n",
    "\n",
    "print(\"Prediction using SensorPredictor:\")\n",
    "print(f\"  Modality: {result['modality']}\")\n",
    "print(f\"  Confidence: {result['confidence']:.1%}\")\n",
    "print(f\"  Probabilities: {result['probabilities']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Time-domain features**: Statistical moments (mean, variance, RMS, skewness, kurtosis) and zero-crossing rate\n",
    "2. **Frequency-domain features**: PSD slope (key noise color discriminator), spectral entropy, flatness, and centroid\n",
    "3. **Stability features**: Allan deviation characterizes sensor stability regimes\n",
    "4. **Feature separability**: Pairwise scatter plots, PCA, and UMAP visualizations show clear modality clustering\n",
    "5. **Classification**: Random Forest achieves high accuracy on sensor modality prediction\n",
    "\n",
    "The saved model can be used via `predictor.py` for real-time sensor modality detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}